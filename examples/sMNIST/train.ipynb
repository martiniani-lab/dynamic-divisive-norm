{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPUs available:  8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import os\n",
    "from training_scripts.sMNIST.model import rnn\n",
    "from training_scripts.sMNIST.dataset import MnistDataModule\n",
    "import training_scripts.sMNIST.default_config as config\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.profilers import PyTorchProfiler\n",
    "\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "\n",
    "print(\"Number of CPUs available: \", torch.get_num_threads())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional RNN cell configurations\n",
    "# kwargs_dict = {\n",
    "#     \"Wr_identity\": False,\n",
    "#     \"learn_tau\": True,\n",
    "#     \"dt_tau_max_y\": 0.05,\n",
    "#     \"dt_tau_max_a\": 0.01,\n",
    "#     \"dt_tau_max_b\": 0.1,\n",
    "# }\n",
    "kwargs_dict = {\n",
    "    \"Wr_identity\": False,\n",
    "    \"learn_tau\": True,\n",
    "    \"dt_tau_max_y\": 0.05,\n",
    "    \"dt_tau_max_a\": 0.01,\n",
    "    \"dt_tau_max_b\": 0.1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the accellerator to cpu for pixel by pixel mnist\n",
    "# config.ACCELERATOR = \"cpu\"\n",
    "# config.DEVICES = 1\n",
    "config.RESIZE = 1.0\n",
    "config.INPUT_SIZE = 1\n",
    "config.SEQUENCE_LENGTH = 784\n",
    "config.LEARNING_RATE = 0.01\n",
    "config.ACCELERATOR = \"gpu\"\n",
    "config.HIDDEN_SIZE = 64\n",
    "config.BATCH_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_from_checkpoint = True\n",
    "folder_name = \"/vast/sr6364/dynamic-divisive-norm/tb_logs/rectified_input/sMNIST\"\n",
    "model_name = \"sMNIST_64_0.05_0.01_0.1_lr_0.01_rectified_input\"\n",
    "logger = TensorBoardLogger(folder_name, name=model_name)\n",
    "# profiler = PyTorchProfiler(\n",
    "#     on_trace_ready=torch.profiler.tensorboard_trace_handler(f\"{folder_name}/profiler0\"),\n",
    "#     schedule=torch.profiler.schedule(skip_first=10, wait=1, warmup=1, active=20),\n",
    "# )\n",
    "dm = MnistDataModule(\n",
    "    data_dir=config.DATA_DIR,\n",
    "    batch_size=config.BATCH_SIZE,\n",
    "    num_workers=config.NUM_WORKERS,\n",
    "    permuted=config.PERMUTED,\n",
    "    resize=config.RESIZE,\n",
    ")\n",
    "model = rnn(\n",
    "    input_size=config.INPUT_SIZE,\n",
    "    hidden_size=config.HIDDEN_SIZE,\n",
    "    seq_length=config.SEQUENCE_LENGTH,\n",
    "    learning_rate=config.LEARNING_RATE,\n",
    "    scheduler_change_step=config.SCHEDULER_CHANGE_STEP,\n",
    "    scheduler_gamma=config.SCHEDULER_GAMMA,\n",
    "    num_classes=config.NUM_CLASSES, \n",
    "    kwargs_dict=kwargs_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0823,  0.1139,  0.2195,  ..., -0.0910,  0.1019,  0.0808],\n",
       "        [-0.0253, -0.0156, -0.1013,  ..., -0.0351,  0.1196,  0.1881],\n",
       "        [ 0.0496, -0.0322, -0.0271,  ..., -0.1848,  0.0458, -0.1236],\n",
       "        ...,\n",
       "        [-0.0200,  0.1312, -0.1303,  ...,  0.1188,  0.0422, -0.0133],\n",
       "        [ 0.0114, -0.0830, -0.1748,  ..., -0.0950,  0.1250, -0.2068],\n",
       "        [-0.0537, -0.0983, -0.1394,  ...,  0.1472,  0.1702,  0.0146]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.org.Wr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    profiler=None,\n",
    "    logger=logger,\n",
    "    accelerator=config.ACCELERATOR,\n",
    "    callbacks=[LearningRateMonitor(logging_interval='epoch'),\n",
    "               ModelCheckpoint(save_top_k=-1, every_n_epochs=1)],\n",
    "    devices=config.DEVICES,\n",
    "    min_epochs=1,\n",
    "    max_epochs=10,\n",
    "    precision=config.PRECISION\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /vast/sr6364/dynamic-divisive-norm/tb_logs/rectified_input/sMNIST/sMNIST_64_0.05_0.01_0.1_lr_0.01_rectified_input/version_8/checkpoints/epoch=0-step=223.ckpt\n",
      "/ext3/miniconda3/envs/feed-r-conda/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:347: The dirpath has changed from '/vast/sr6364/dynamic-divisive-norm/tb_logs/rectified_input/sMNIST/sMNIST_64_0.05_0.01_0.1_lr_0.01_rectified_input/version_8/checkpoints' to '/vast/sr6364/dynamic-divisive-norm/tb_logs/rectified_input/sMNIST/sMNIST_64_0.05_0.01_0.1_lr_0.01_rectified_input/version_9/checkpoints', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type               | Params\n",
      "------------------------------------------------\n",
      "0 | org      | rnnCell            | 25.1 K\n",
      "1 | fc       | Linear             | 650   \n",
      "2 | loss_fn  | CrossEntropyLoss   | 0     \n",
      "3 | accuracy | MulticlassAccuracy | 0     \n",
      "------------------------------------------------\n",
      "25.7 K    Trainable params\n",
      "64        Non-trainable params\n",
      "25.7 K    Total params\n",
      "0.103     Total estimated model params size (MB)\n",
      "Restored all states from the checkpoint at /vast/sr6364/dynamic-divisive-norm/tb_logs/rectified_input/sMNIST/sMNIST_64_0.05_0.01_0.1_lr_0.01_rectified_input/version_8/checkpoints/epoch=0-step=223.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5adbb48f5666412ea1ffbb8656bef32d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4eaea078c204761a2126d91cf33e57e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "torch.linalg.eig: input tensor should not contain infs or NaNs.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m         max_idx \u001b[38;5;241m=\u001b[39m epoch_idx\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;28mmax\u001b[39m(epoch_idx))\n\u001b[1;32m     14\u001b[0m     checkpoint_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(checkpoint_folder, checkpoint_files[max_idx])\n\u001b[0;32m---> 15\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mfit(model, dm)\n",
      "File \u001b[0;32m/ext3/miniconda3/envs/feed-r-conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:544\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/ext3/miniconda3/envs/feed-r-conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m/ext3/miniconda3/envs/feed-r-conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:580\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    574\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    576\u001b[0m     ckpt_path,\n\u001b[1;32m    577\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    578\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    579\u001b[0m )\n\u001b[0;32m--> 580\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/ext3/miniconda3/envs/feed-r-conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:989\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    986\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 989\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    994\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/ext3/miniconda3/envs/feed-r-conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1035\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_sanity_check()\n\u001b[1;32m   1034\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1035\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/ext3/miniconda3/envs/feed-r-conda/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:202\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 202\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/ext3/miniconda3/envs/feed-r-conda/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:359\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 359\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/ext3/miniconda3/envs/feed-r-conda/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py:136\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 136\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/ext3/miniconda3/envs/feed-r-conda/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py:240\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mautomatic_optimization:\n\u001b[1;32m    239\u001b[0m         \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[0;32m--> 240\u001b[0m         batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautomatic_optimization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    242\u001b[0m         batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanual_optimization\u001b[38;5;241m.\u001b[39mrun(kwargs)\n",
      "File \u001b[0;32m/ext3/miniconda3/envs/feed-r-conda/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:187\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[0;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m         closure()\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 187\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m result \u001b[38;5;241m=\u001b[39m closure\u001b[38;5;241m.\u001b[39mconsume_result()\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/ext3/miniconda3/envs/feed-r-conda/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:265\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[0;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_progress\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mincrement_ready()\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_progress\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mincrement_completed()\n",
      "File \u001b[0;32m/ext3/miniconda3/envs/feed-r-conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:157\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m hook_name\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 157\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    160\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m/ext3/miniconda3/envs/feed-r-conda/lib/python3.10/site-packages/pytorch_lightning/core/module.py:1291\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimizer_step\u001b[39m(\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1254\u001b[0m     epoch: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1257\u001b[0m     optimizer_closure: Optional[Callable[[], Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1258\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[1;32m   1260\u001b[0m \u001b[38;5;124;03m    the optimizer.\u001b[39;00m\n\u001b[1;32m   1261\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1289\u001b[0m \n\u001b[1;32m   1290\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1291\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/ext3/miniconda3/envs/feed-r-conda/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py:151\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `optimizer.step(closure)` is called, the closure should be callable\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 151\u001b[0m step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_after_step()\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m step_output\n",
      "File \u001b[0;32m/ext3/miniconda3/envs/feed-r-conda/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:230\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[0;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl\u001b[38;5;241m.\u001b[39mLightningModule)\n\u001b[0;32m--> 230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/ext3/miniconda3/envs/feed-r-conda/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py:117\u001b[0m, in \u001b[0;36mPrecision.optimizer_step\u001b[0;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Hook to run the optimizer step.\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m closure \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_closure, model, optimizer, closure)\n\u001b[0;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/ext3/miniconda3/envs/feed-r-conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:68\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     67\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/ext3/miniconda3/envs/feed-r-conda/lib/python3.10/site-packages/torch/optim/optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    370\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m             )\n\u001b[0;32m--> 373\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/ext3/miniconda3/envs/feed-r-conda/lib/python3.10/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m/ext3/miniconda3/envs/feed-r-conda/lib/python3.10/site-packages/torch/optim/adam.py:143\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m--> 143\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[1;32m    146\u001b[0m     params_with_grad \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/ext3/miniconda3/envs/feed-r-conda/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py:104\u001b[0m, in \u001b[0;36mPrecision._wrap_closure\u001b[0;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap_closure\u001b[39m(\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     93\u001b[0m     model: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.LightningModule\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     94\u001b[0m     optimizer: Optimizer,\n\u001b[1;32m     95\u001b[0m     closure: Callable[[], Any],\n\u001b[1;32m     96\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m     97\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the ``on_before_optimizer_step``\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m    hook is called.\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    102\u001b[0m \n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m     closure_result \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_closure(model, optimizer)\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m closure_result\n",
      "File \u001b[0;32m/ext3/miniconda3/envs/feed-r-conda/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:140\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Tensor]:\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mloss\n",
      "File \u001b[0;32m/ext3/miniconda3/envs/feed-r-conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/ext3/miniconda3/envs/feed-r-conda/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:135\u001b[0m, in \u001b[0;36mClosure.closure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_zero_grad_fn()\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m step_output\u001b[38;5;241m.\u001b[39mclosure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m step_output\n",
      "File \u001b[0;32m/ext3/miniconda3/envs/feed-r-conda/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:236\u001b[0m, in \u001b[0;36m_AutomaticOptimization._make_backward_fn.<locals>.backward_fn\u001b[0;34m(loss)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward_fn\u001b[39m(loss: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 236\u001b[0m     \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbackward\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/ext3/miniconda3/envs/feed-r-conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:309\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 309\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    312\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m/ext3/miniconda3/envs/feed-r-conda/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:206\u001b[0m, in \u001b[0;36mStrategy.backward\u001b[0;34m(self, closure_loss, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m closure_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mpre_backward(closure_loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module)\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mbackward(closure_loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, optimizer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 206\u001b[0m closure_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_backward(closure_loss)\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m closure_loss\n",
      "File \u001b[0;32m/ext3/miniconda3/envs/feed-r-conda/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py:76\u001b[0m, in \u001b[0;36mPrecision.post_backward\u001b[0;34m(self, tensor, module)\u001b[0m\n\u001b[1;32m     74\u001b[0m trainer \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39mtrainer\n\u001b[1;32m     75\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(trainer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_after_backward\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 76\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mon_after_backward\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m closure_loss\n",
      "File \u001b[0;32m/ext3/miniconda3/envs/feed-r-conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:157\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m hook_name\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 157\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    160\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/python_scripts/dynamic-divisive-norm/training_scripts/sMNIST/model.py:197\u001b[0m, in \u001b[0;36mrnn.on_after_backward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mexperiment\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgradient_norm\u001b[39m\u001b[38;5;124m\"\u001b[39m, total_norm, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_step)\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# Log the spectral radius of Wr\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m eigvals \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meigvals\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m spectral_radius \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(torch\u001b[38;5;241m.\u001b[39mabs(eigvals))\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mexperiment\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspectral_radius_Wr\u001b[39m\u001b[38;5;124m\"\u001b[39m, spectral_radius, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_step)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: torch.linalg.eig: input tensor should not contain infs or NaNs."
     ]
    }
   ],
   "source": [
    "if start_from_checkpoint:\n",
    "    version = 8\n",
    "    epoch_no = None\n",
    "    checkpoint_folder = f'{folder_name}/{model_name}/version_{version}/checkpoints/'\n",
    "    checkpoint_files = os.listdir(checkpoint_folder)\n",
    "    epoch_idx = [int(file.split('epoch=')[1].split('-')[0]) for file in checkpoint_files]\n",
    "    if epoch_no is not None:\n",
    "        # If epoch number is provided, find the index of that epoch\n",
    "        max_idx = epoch_idx.index(epoch_no)\n",
    "    else:\n",
    "        # If epoch number is not provided, find the index of the max epoch\n",
    "        max_idx = epoch_idx.index(max(epoch_idx))\n",
    "\n",
    "    checkpoint_path = os.path.join(checkpoint_folder, checkpoint_files[max_idx])\n",
    "    trainer.fit(model, dm, ckpt_path=checkpoint_path)\n",
    "else:\n",
    "    trainer.fit(model, dm)\n",
    "\n",
    "# trainer.validate(model, dm)\n",
    "# trainer.test(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e65c4a2075d41f899f07b436686329b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.21130000054836273\n",
      "         test_f1            0.21130000054836273\n",
      "        test_loss            2.211268663406372\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_acc': 0.21130000054836273,\n",
       "  'test_f1': 0.21130000054836273,\n",
       "  'test_loss': 2.211268663406372}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "import torch\n",
    "\n",
    "n = 10\n",
    "mat = torch.eye(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "nn.init.orthogonal_(mat, gain=2.0)\n",
    "\n",
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7fc6dff93a00>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# imshow mat\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(mat)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectral norm of the matrix: 2.000000476837158\n"
     ]
    }
   ],
   "source": [
    "# find the spectral norm of the matrix\n",
    "spectral_norm = torch.svd(mat).S[0].item()\n",
    "print(f\"Spectral norm of the matrix: {spectral_norm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectral norm of the matrix: 1.0\n"
     ]
    }
   ],
   "source": [
    "mat = mat / spectral_norm\n",
    "\n",
    "spectral_norm = torch.svd(mat).S[0].item()\n",
    "print(f\"Spectral norm of the matrix: {spectral_norm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
